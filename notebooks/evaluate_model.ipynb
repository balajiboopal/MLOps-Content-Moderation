{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy: 0.40\n",
      "‚úÖ Precision: 0.00\n",
      "‚úÖ Recall: 0.00\n",
      "‚úÖ F1 Score: 0.00\n",
      "\n",
      "üîç Sample Predictions:\n",
      "                  text  label  predicted\n",
      "0     You are amazing!      0          0\n",
      "1          I hate you!      1          0\n",
      "2   This is so stupid!      1          0\n",
      "3          I love this      0          0\n",
      "4    This is an insult      1          0\n",
      "5   What a great idea!      0          0\n",
      "6  Shut up, you idiot!      1          0\n",
      "7    You are worthless      1          0\n",
      "8           Thank you!      0          0\n",
      "9      Go away, loser!      1          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/balajiboopal/Documents/Projects/content_moderation_system/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pre-trained model\n",
    "MODEL_NAME = \"unitary/toxic-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Larger dataset for better evaluation\n",
    "test_data = pd.DataFrame({\n",
    "    \"text\": [\n",
    "        \"You are amazing!\", \"I hate you!\", \"This is so stupid!\",\n",
    "        \"I love this\", \"This is an insult\", \"What a great idea!\",\n",
    "        \"Shut up, you idiot!\", \"You are worthless\", \"Thank you!\",\n",
    "        \"Go away, loser!\"\n",
    "    ],\n",
    "    \"label\": [0, 1, 1, 0, 1, 0, 1, 1, 0, 1]  # 0 = non-toxic, 1 = toxic\n",
    "})\n",
    "\n",
    "# Function for batch processing\n",
    "def batch_predict(text_list):\n",
    "    \"\"\"Predicts toxicity for a batch of texts.\"\"\"\n",
    "    inputs = tokenizer(text_list, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():  # Disable gradients for faster inference\n",
    "        outputs = model(**inputs)\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[:, 1]  # Take toxic probability\n",
    "    return (probabilities > 0.5).int().tolist()  # Convert to binary classification (0 or 1)\n",
    "\n",
    "# Predict in batch\n",
    "test_data[\"predicted\"] = batch_predict(test_data[\"text\"].tolist())\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(test_data[\"label\"], test_data[\"predicted\"])\n",
    "precision = precision_score(test_data[\"label\"], test_data[\"predicted\"])\n",
    "recall = recall_score(test_data[\"label\"], test_data[\"predicted\"])\n",
    "f1 = f1_score(test_data[\"label\"], test_data[\"predicted\"])\n",
    "\n",
    "# Display results\n",
    "print(f\"‚úÖ Accuracy: {accuracy:.2f}\")\n",
    "print(f\"‚úÖ Precision: {precision:.2f}\")\n",
    "print(f\"‚úÖ Recall: {recall:.2f}\")\n",
    "print(f\"‚úÖ F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Print sample predictions for manual review\n",
    "print(\"\\nüîç Sample Predictions:\")\n",
    "print(test_data[[\"text\", \"label\", \"predicted\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0             0        0       0       0              0  \n",
      "1             0        0       0       0              0  \n",
      "2             0        0       0       0              0  \n",
      "3             0        0       0       0              0  \n",
      "4             0        0       0       0              0  \n",
      "(159571, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "# Check the first few rows\n",
    "print(df.head())\n",
    "print(df.shape)  # Should be (159571, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
